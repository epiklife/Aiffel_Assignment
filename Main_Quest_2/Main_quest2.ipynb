{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQIgGHNwAcl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58a9664-cd8c-4b0b-fd30-e0b15f732960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "\n"
      ],
      "metadata": {
        "id": "_8WNIBYRDHLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = image_dataset_from_directory(\n",
        "   '/content/drive/MyDrive/Colab Notebooks/chest_xray/train',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "   '/content/drive/MyDrive/Colab Notebooks/chest_xray/val',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "test_dataset = image_dataset_from_directory(\n",
        "   '/content/drive/MyDrive/Colab Notebooks/chest_xray/test',\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a2MP1ZngZmt",
        "outputId": "11646153-357b-4758-a33a-05270ccda4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5216 files belonging to 2 classes.\n",
            "Found 16 files belonging to 2 classes.\n",
            "Found 624 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2)\n",
        "    ]\n",
        ")\n",
        "\n",
        "def residual_block(x, filters, stride=1):\n",
        "    residual = x\n",
        "\n",
        "    if stride != 1 or x.shape[-1] != filters:\n",
        "        residual = layers.Conv2D(filters, 1, strides=stride)(residual)\n",
        "        residual = layers.BatchNormalization()(residual)\n",
        "\n",
        "    x = layers.Conv2D(filters, 3, padding='same', strides=stride)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    x = layers.Add()([x, residual])\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def build_resnet(input_shape, num_classes=1):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Conv2D(32, 7, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
        "\n",
        "    x = residual_block(x, 32)\n",
        "    x = residual_block(x, 64, stride=2)\n",
        "    x = residual_block(x, 128, stride=2)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    return keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "nyazVKfLgTRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_resnet((224, 224, 3))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "CD8A82r0i8HW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "ijDqcY0Fq9_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIzq6ta-r1aI",
        "outputId": "9a6f7955-516f-4b5f-8959-2538d990e1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)      (None, 224, 224, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 112, 112, 32  4736        ['sequential_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 112, 112, 32  128        ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 112, 112, 32  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 32)  0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 56, 56, 32)   9248        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 56, 56, 32)  128         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 56, 56, 32)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 56, 56, 32)   9248        ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 56, 56, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 56, 56, 32)   0           ['batch_normalization_11[0][0]', \n",
            "                                                                  'max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 56, 56, 32)   0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 28, 28, 64)   18496       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 28, 28, 64)  256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 28, 28, 64)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 28, 28, 64)   36928       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 28, 28, 64)   2112        ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 28, 28, 64)  256         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 28, 28, 64)  256         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 28, 28, 64)   0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 28, 28, 64)   0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 14, 14, 128)  73856       ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 14, 14, 128)  512        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 14, 14, 128)  147584      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 14, 14, 128)  8320        ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 14, 14, 128)  512        ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 14, 14, 128)  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 14, 14, 128)  0           ['batch_normalization_17[0][0]', \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 14, 14, 128)  0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " global_average_pooling2d_1 (Gl  (None, 128)         0           ['activation_13[0][0]']          \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            129         ['global_average_pooling2d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 313,345\n",
            "Trainable params: 312,001\n",
            "Non-trainable params: 1,344\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=validation_dataset,\n",
        "    epochs=10,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir0eisBRi_u-",
        "outputId": "32913002-fa9a-4568-aef0-0367ca44bdfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "163/163 [==============================] - 874s 5s/step - loss: 0.2640 - accuracy: 0.8861 - val_loss: 7.6572 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "163/163 [==============================] - 40s 238ms/step - loss: 0.1951 - accuracy: 0.9241 - val_loss: 10.2439 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "163/163 [==============================] - 39s 229ms/step - loss: 0.1722 - accuracy: 0.9304 - val_loss: 1.2005 - val_accuracy: 0.3750\n",
            "Epoch 4/10\n",
            "163/163 [==============================] - 41s 244ms/step - loss: 0.1594 - accuracy: 0.9400 - val_loss: 4.4308 - val_accuracy: 0.5000\n",
            "Epoch 5/10\n",
            "163/163 [==============================] - 39s 226ms/step - loss: 0.1458 - accuracy: 0.9473 - val_loss: 1.5065 - val_accuracy: 0.4375\n",
            "Epoch 6/10\n",
            "163/163 [==============================] - 40s 230ms/step - loss: 0.1432 - accuracy: 0.9448 - val_loss: 2.5963 - val_accuracy: 0.5625\n",
            "Epoch 7/10\n",
            "163/163 [==============================] - 40s 237ms/step - loss: 0.1274 - accuracy: 0.9551 - val_loss: 21.2882 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "163/163 [==============================] - 40s 236ms/step - loss: 0.1214 - accuracy: 0.9563 - val_loss: 1.2668 - val_accuracy: 0.3750\n",
            "Epoch 9/10\n",
            "163/163 [==============================] - 40s 236ms/step - loss: 0.1190 - accuracy: 0.9567 - val_loss: 4.2644 - val_accuracy: 0.5000\n",
            "Epoch 10/10\n",
            "163/163 [==============================] - 41s 244ms/step - loss: 0.1098 - accuracy: 0.9584 - val_loss: 27.2814 - val_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f19f41a5db0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "log_dir = \"logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "metadata": {
        "id": "WekhtWjx0P_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "etR6G7NTyhPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir=/content/logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "v-b5cYro4wyW",
        "outputId": "bffae03e-3a05-4332-8c6d-e4e512a1c423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "2023-06-22 06:57:44.125589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
              "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.33' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
              "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.34' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
              "/usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.32' not found (required by /usr/local/lib/python3.10/dist-packages/tensorboard_data_server/bin/server)\n",
              "Address already in use\n",
              "Port 6006 is in use by another program. Either identify and stop that program, or start the server with a different port."
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BLgbtkHM4x2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorboard dev upload --logdir /content/logs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRJdSUhV5RKV",
        "outputId": "16bd8839-86c2-4431-c127-80b2ecc6cdf6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-22 07:05:39.224527: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "***** TensorBoard Uploader *****\n",
            "\n",
            "This will upload your TensorBoard logs to https://tensorboard.dev/ from\n",
            "the following directory:\n",
            "\n",
            "/content/logs\n",
            "\n",
            "This TensorBoard will be visible to everyone. Do not upload sensitive\n",
            "data.\n",
            "\n",
            "Your use of this service is subject to Google's Terms of Service\n",
            "<https://policies.google.com/terms> and Privacy Policy\n",
            "<https://policies.google.com/privacy>, and TensorBoard.dev's Terms of Service\n",
            "<https://tensorboard.dev/policy/terms/>.\n",
            "\n",
            "This notice will not be shown again while you are logged into the uploader.\n",
            "To log out, run `tensorboard dev auth revoke`.\n",
            "\n",
            "Continue? (yes/NO) yes\n",
            "\n",
            "To sign in with the TensorBoard uploader:\n",
            "\n",
            "1. On your computer or phone, visit:\n",
            "\n",
            "   https://www.google.com/device\n",
            "\n",
            "2. Sign in with your Google account, then enter:\n",
            "\n",
            "   QFT-TBQ-RZT\n",
            "\n",
            "QFT-TBQ-RZT\n",
            "\n",
            "Upload started and will continue reading any new data as it's added to the logdir.\n",
            "\n",
            "To stop uploading, press Ctrl-C.\n",
            "\n",
            "New experiment created. View your TensorBoard at: https://tensorboard.dev/experiment/pYhaNzMVTDOXMcN7QJJEUg/\n",
            "\n",
            "\u001b[1m[2023-06-22T07:06:25]\u001b[0m Started scanning logdir.\n",
            "\u001b[1m[2023-06-22T07:06:29]\u001b[0m Total uploaded: 60 scalars, 560 tensors (402.0 kB), 3 binary objects (902.0 kB)\n",
            "\n",
            "\n",
            "Interrupted. View your TensorBoard at https://tensorboard.dev/experiment/pYhaNzMVTDOXMcN7QJJEUg/\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/main.py\", line 46, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/program.py\", line 276, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 691, in run\n",
            "    return _run(flags, self._experiment_url_callback)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/uploader/uploader_subcommand.py\", line 123, in _run\n",
            "    with channel:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\", line 1746, in __exit__\n",
            "    self._close()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/grpc/_channel.py\", line 1732, in _close\n",
            "    self._channel.close(cygrpc.StatusCode.cancelled, 'Channel closed!')\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 513, in grpc._cython.cygrpc.Channel.close\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 399, in grpc._cython.cygrpc._close\n",
            "  File \"src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi\", line 429, in grpc._cython.cygrpc._close\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 389, in notify_all\n",
            "    def notify_all(self):\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}