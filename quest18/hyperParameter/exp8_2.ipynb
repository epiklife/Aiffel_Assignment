{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c90b78fc",
   "metadata": {},
   "source": [
    "### 한국어 데이터로 챗봇 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443e6995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927035c",
   "metadata": {},
   "source": [
    "#### Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6d1679",
   "metadata": {},
   "source": [
    "songys/Chatbot_data(https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv) 에서 한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d58456d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/ChatbotData.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8c4643",
   "metadata": {},
   "source": [
    "#### Step 2. 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9a750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    # 입력받은 sentence를 소문자로 변경하고 양쪽 공백을 제거\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    # 단어와 구두점(punctuation) 사이의 거리를 만듭니다.\n",
    "    # 예를 들어서 \"나는 학생입니다.\" => \"나는 학생 입니다 .\"와 같이\n",
    "    # 학생과 마침표 사이에 거리를 만듭니다.\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "\n",
    "    # (ㄱㅎ가-힣, \".\", \"?\", \"!\", \",\")를 제외한 모든 문자를 공백인 ' '로 대체합니다.\n",
    "#     sentence = re.sub(r\"[^ㄱ-ㅎ가-힣?.!,]+\", \" \", sentence)\n",
    "    sentence = re.sub(r\"[^0-9ㄱ-ㅎ가-힣?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694119dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문과 답변의 쌍인 데이터셋을 구성하기 위한 데이터 로드 함수\n",
    "def load_conversations(_data):\n",
    "    Q = _data['Q']\n",
    "    A = _data['A']\n",
    "    Label = _data['label']\n",
    "\n",
    "\n",
    "    Q = [preprocess_sentence(q) for q in _data['Q']]\n",
    "    A = [preprocess_sentence(a) for a in _data['A']]\n",
    "    return Q, A, Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c0b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 수 : 11823\n",
      "전체 샘플 수 : 11823\n",
      "전처리 후의 22번째 질문 샘플: 1지망 학교 떨어졌어\n",
      "전처리 후의 22번째 답변 샘플: 위로해 드립니다 .\n"
     ]
    }
   ],
   "source": [
    "questions, answers, label = load_conversations(data)\n",
    "print('전체 샘플 수 :', len(questions))\n",
    "print('전체 샘플 수 :', len(answers))\n",
    "\n",
    "print('전처리 후의 22번째 질문 샘플: {}'.format(questions[1]))\n",
    "print('전처리 후의 22번째 답변 샘플: {}'.format(answers[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea0d09",
   "metadata": {},
   "source": [
    "#### Step 3. SubwordTextEncoder 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e9f3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성\n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2cbd578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8158]\n",
      "END_TOKEN의 번호 : [8159]\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여합니다.\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c696f1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8160\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "833a9eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAaCUlEQVR4nO3de7QmVXnn8e+PRi4iCkiHQDfSqBhvoyQh4i0JywsgmuAkanCZpDE4JFm6hqyJUTROJEQjGhXNLC/BgCJegOUldjQOENQ4xgg0iCj0OLYI0i1CS3P1QgSf+aP2wdfjOad3d5/33Pr7WetdXbWr3l1PnepTz9m7qnalqpAkqcdO8x2AJGnxMGlIkrqZNCRJ3UwakqRuJg1JUjeThiSpm0lDGpHkuiTPmIftrkpSSXbexu8fn+QLI/N3JXnoLMX26iT/OBtxTlH3Q1qsy2ajPo2fSUMzSvLUJF9McnuSzUn+PcmvzUK9P3OS29GMOzlV1QOq6totxHBEkg0ddf1tVb1kNuKavN9V9e0W672zUb/Gb1b+WtDSlOSBwCeBPwXOB3YBfh24ez7j0txJsnNV3TPfcWjhsKWhmTwCoKo+XFX3VtUPq+rCqrpqYoUkf5RkXZJbk1yQ5KCRZZXkT5J8I8ltSd6RwaOAdwNPal0Tt7X1d03y5iTfTnJTkncn2b0tOyLJhiR/nuTmJDcmefHItnZP8pYk17dW0RdGvvvE1lq6LclXkhzRs/NJdkpycpJvJrklyflJ9mnLJrppVrd4v5fkLyfFc3b7uaxL8oqJv+qTnAM8BPjntv+vGNnsi6aqb4rYHpxkTZI7klwKPGzS8kry8DZ9TJJrktyZZGOSlyfZA/g0cECL4a4kByQ5JclHknwgyR3A8a3sA5NC+KMk32nH4eUj231fkteNzN/Xmplqvyd3d7UY1rRW7fok/22krlPaMXh/25erkxy25SOpWVVVfvxM+QEeCNwCnA08C9h70vJjgfXAoxhara8BvjiyvBhaKnsxnCw2AUe3ZccDX5hU3+nAGmAfYE/gn4E3tGVHAPcApwL3A44BfjARE/AO4HPACmAZ8GRg1zZ/S1t/J+CZbX75NPt8HfCMNn0S8CVgZavrH4APt2Wr2v69B9gdeDxDC+xRbflpwL8Be7fvXwVsmGo7PfVNEee5DK2/PYDHAhtHf56troe36RuBX2/TewO/MvIz3TCp3lOAHwPPbT+v3VvZBybF+eG27f/SjuvEz+x9wOtG6vuZbcyw3zu3+c8D7wR2Aw5tdT9tJLYftWO5DHgD8KX5/j3Z0T7zHoCfhf1hSAjvAzYwnLTXAPu1ZZ8GThhZdyeGE/lBbb6Ap44sPx84uU0fP+kkF+D7wMNGyp4EfKtNHwH8cOLk0spuBp7YtvtD4PFTxP9K4JxJZRcAq6fZ3/tOasA64Okjy/ZvJ9SdR052K0eWXwoc16avBY4aWfaSzpPnlPVNinFZi+ORI2V/y/RJ49vAHwMPnFTPz5zQW9kpwOenKJucNEa3/SbgzDb9PrYxaQAHAvcCe44sfwPwvpE4/nVk2aOBH87378iO9rF7SjOqqnVVdXxVrWT4i/YA4G1t8UHA21u3z23AZoaT/4qRKr47Mv0D4AHTbGo5cH/g8pH6/ncrn3BL/Wz/+kR9+zL8ZfrNKeo9CHj+RJ2t3qcyJIAtOQj4+Mj31jGc1Pbr2L8DgBtGlo1Oz6Tn57Wc4SQ7Wuf1M9T5uwx/nV+f5N+SPGkLMfTEOnnbB3R8Z0sOADZX1Z2T6p7p/9NumaU7udTHpKFuVfV/Gf6SfGwrugH446raa+Sze1V9sae6SfPfY2gtPGakrgdV1XRJZvJ3f8Skfv2RGM+ZFOMeVXVaR703AM+a9N3dqmpjx3dvZOiWmnDgpOXbM7z0JoZW32idD5lu5aq6rKqOBX4B+CeGFt9MMfTENnnb32nT32dI/hN+cSvq/g6wT5I9J9Xd8/PWHDFpaFpJHtkuPK9s8wcCL2To54fhYvarkjymLX9Qkud3Vn8TsDLJLgBV9ROG/vzTk/xCq29FkqO2VFH77lnAW9uF1GVJnpRkV+ADwG8lOaqV79Yuzq6cudb79u/1aRf3kyxPcmzn/p3P8LPZO8kK4GWTlt8EbNNzFDXcnvox4JQk90/yaGD1VOsm2SXJi5I8qKp+DNwB/GQkhgcnedA2hPE/27YfA7wYOK+VXwkck2SfJL8I/Nmk702731V1A/BF4A3tOD0OOIHhGGqBMGloJncChwOXJPk+Q7L4GvDnAFX1ceCNwLntTpuvMVww7/EZ4Grgu0m+18peyXBh/Uutvn8FfqmzvpcDXwUuY+gmeyOwUzsRHQu8muEv9BuAv6Dv//7bGa7hXJjkTob9P7wznlMZrgN9q+3HR/jZW5XfALymdX29fIrvb8nLGLquvsvQ+nvvDOv+AXBd+5n+CfAiuK/l+GHg2hbH1nQx/RvDsboYeHNVXdjKzwG+wnDt4kJ+mkwmbGm/X8hwneM7wMeB11bVv25FXBqzVPkSJmnckvwpw0Xt35zvWKTtYUtDGoMk+yd5SoZnPX6JoXX28fmOS9pe3nUgjccuDM91HAzcxvBcxTvnMyBpNtg9JUnqZveUJKnbkuye2nfffWvVqlXzHYYkLSqXX37596pq+UzrLMmksWrVKtauXTvfYUjSopJkppEFALunJElbwaQhSepm0pAkdTNpSJK6mTQkSd1MGpKkbiYNSVI3k4YkqZtJQ5LUbUk+Eb5YrTr5U1OWX3fas+c4Ekmami0NSVI3k4YkqZtJQ5LUzaQhSepm0pAkdfPuqUXMu60kzTVbGpKkbiYNSVI3k4YkqZtJQ5LUzaQhSepm0pAkdTNpSJK6mTQkSd1MGpKkbiYNSVI3k4YkqdvYk0aSZUm+nOSTbf7gJJckWZ/kvCS7tPJd2/z6tnzVSB2vauVfT3LUuGOWJE1tLloaJwHrRubfCJxeVQ8HbgVOaOUnALe28tPbeiR5NHAc8BjgaOCdSZbNQdySpEnGmjSSrASeDfxjmw/wNOAjbZWzgee26WPbPG3509v6xwLnVtXdVfUtYD3whHHGLUma2rhbGm8DXgH8pM0/GLitqu5p8xuAFW16BXADQFt+e1v/vvIpvnOfJCcmWZtk7aZNm2Z5NyRJMMakkeQ5wM1Vdfm4tjGqqs6oqsOq6rDly5fPxSYlaYczzpcwPQX47STHALsBDwTeDuyVZOfWmlgJbGzrbwQOBDYk2Rl4EHDLSPmE0e9IkubQ2FoaVfWqqlpZVasYLmR/pqpeBHwWeF5bbTXwiTa9ps3Tln+mqqqVH9furjoYOAS4dFxxS5KmNx+ve30lcG6S1wFfBs5s5WcC5yRZD2xmSDRU1dVJzgeuAe4BXlpV98592JKkOUkaVfU54HNt+lqmuPupqn4EPH+a778eeP34IpQk9fCJcElSN5OGJKmbSUOS1M2kIUnqZtKQJHUzaUiSupk0JEndTBqSpG4mDUlSN5OGJKmbSUOS1M2kIUnqZtKQJHUzaUiSupk0JEndTBqSpG4mDUlSN5OGJKmbSUOS1M2kIUnqZtKQJHUzaUiSupk0JEndTBqSpG4mDUlSN5OGJKnbzvMdgGbfqpM/NWX5dac9e44jkbTU2NKQJHUzaUiSupk0JEndTBqSpG5eCB8jL0hLWmpsaUiSupk0JEndTBqSpG4mDUlSN5OGJKnb2JJGkt2SXJrkK0muTvLXrfzgJJckWZ/kvCS7tPJd2/z6tnzVSF2vauVfT3LUuGKWJM1snC2Nu4GnVdXjgUOBo5M8EXgjcHpVPRy4FTihrX8CcGsrP72tR5JHA8cBjwGOBt6ZZNkY45YkTWNsSaMGd7XZ+7VPAU8DPtLKzwae26aPbfO05U9PklZ+blXdXVXfAtYDTxhX3JKk6Y31mkaSZUmuBG4GLgK+CdxWVfe0VTYAK9r0CuAGgLb8duDBo+VTfGd0WycmWZtk7aZNm8awN5KksSaNqrq3qg4FVjK0Dh45xm2dUVWHVdVhy5cvH9dmJGmHNid3T1XVbcBngScBeyWZGL5kJbCxTW8EDgRoyx8E3DJaPsV3JElzaJx3Ty1Psleb3h14JrCOIXk8r622GvhEm17T5mnLP1NV1cqPa3dXHQwcAlw6rrglSdMb54CF+wNntzuddgLOr6pPJrkGODfJ64AvA2e29c8EzkmyHtjMcMcUVXV1kvOBa4B7gJdW1b1jjFuSNI2xJY2qugr45SnKr2WKu5+q6kfA86ep6/XA62c7RknS1vGJcElSN5OGJKmbSUOS1G2LSSPJ5UlemmTvuQhIkrRw9bQ0fg84ALgsyblJjmrDe0iSdjBbTBpVtb6q/hJ4BPAh4Czg+iR/nWSfcQcoSVo4uq5pJHkc8Bbg74CPMtwaewfwmfGFJklaaLb4nEaSy4HbGB6+O7mq7m6LLknylDHGJklaYHoe7nt+eyDv51TV78xyPJKkBayne+olE2NIASTZuw0BIknawfQkjWe1UWoBqKpbgWPGFpEkacHqSRrLkuw6MdNGrN11hvUlSUtUzzWNDwIXJ3lvm38xP30tqyRpB7LFpFFVb0xyFfD0VvQ3VXXBeMOSJC1EXUOjV9WngU+PORZJ0gLXM/bU7yT5RpLbk9yR5M4kd8xFcJKkhaWnpfEm4Leqat24g5EkLWw9d0/dZMKQJEFfS2NtkvOAfwImhhChqj42rqA0t1ad/Klpl1132rPnMBJJC11P0ngg8APgyJGyAkwakrSD6bnl9sVzEYgkaeHruXvqEUkuTvK1Nv+4JK8Zf2iSpIWm50L4e4BXAT8GqKqrgOPGGZQkaWHqSRr3r6pLJ5XdM45gJEkLW0/S+F6ShzFc/CbJ84AbxxqVJGlB6rl76qXAGcAjk2wEvgX8/lijkiQtSD13T10LPCPJHsBOVXXn+MOSJC1EPe8I/6tJ8wBU1aljikmStED1dE99f2R6N+A5gMOKSNIOqKd76i2j80neDPg+DUnaAfXcPTXZ/YGVsx2IJGnh67mm8VXa7bbAMmA54PUMSdoB9VzTeM7I9D0MQ6X7cJ8k7YB6ksbkW2wfOHEHFUBVbZ7ViCRJC1ZP0rgCOBC4FQiwF/DttqyAh44lMknSgtNzIfwihte97ltVD2borrqwqg6uKhOGJO1AepLGE6vqXyZmqurTwJPHF5IkaaHq6Z76Tnt/xgfa/IuA74wvJEnSQtXT0nghw222H2d4xevyVjajJAcm+WySa5JcneSkVr5PkouSfKP9u3crT5K/T7I+yVVJfmWkrtVt/W8kWb0tOypJ2n49T4RvBk5KskdVfX9L64+4B/jzqroiyZ7A5UkuAo4HLq6q05KcDJwMvBJ4FnBI+xwOvAs4PMk+wGuBwxguvF+eZE1V3boVsUiSZkHP616fnOQa2nhTSR6f5J1b+l5V3VhVV7TpO9v3VwDHAme31c4GntumjwXeX4MvAXsl2R84Crioqja3RHERcPRW7KMkaZb0dE+dznDivgWgqr4C/MbWbCTJKuCXgUuA/apq4iVO3wX2a9MrgBtGvrahlU1XPnkbJyZZm2Ttpk2btiY8SVKnrrGnquqGSUX39m4gyQOAjwJ/VlV3TKq3+OkQJdulqs6oqsOq6rDly5fPRpWSpEl6ksYNSZ4MVJL7JXk5nUOjJ7kfQ8L4YFV9rBXf1LqdaP/e3Mo3MjxEOGFlK5uuXJI0x3qSxp8wvPJ1BcPJ+tA2P6MMY42cCayrqreOLFoDTNwBtRr4xEj5H7a7qJ4I3N66sS4Ajkyyd7vT6kgcml2S5sWMd08lWQa8vapetA11PwX4A+CrSa5sZa8GTgPOT3ICcD3wgrbsX4BjgPXAD4AXw3D3VpK/AS5r653qeFeSND9mTBpVdW+Sg5LsUlX/uTUVV9UXGMaqmsrTp1i/mKYFU1VnAWdtzfYlSbOv54nwa4F/T7KGkVe/TupykiTtAKa9ppHknDb528An27p7jnwkSTuYmVoav5rkAIZh0P/XHMUjSVrAZkoa7wYuBg4G1o6UB9+jIUk7pGm7p6rq76vqUcB7q+qhIx/foyFJO6gtPqdRVX86F4FIkha+rmFEJEkCk4YkaSuYNCRJ3UwakqRuJg1JUreeYUSkn7Pq5E9NWX7dac+e40gkzSVbGpKkbiYNSVI3k4YkqZtJQ5LUzaQhSepm0pAkdTNpSJK6mTQkSd1MGpKkbiYNSVI3k4YkqZtJQ5LUzaQhSepm0pAkdTNpSJK6mTQkSd1MGpKkbiYNSVI3k4YkqZvvCNec8J3i0tJgS0OS1M2kIUnqZtKQJHUzaUiSupk0JEndxnb3VJKzgOcAN1fVY1vZPsB5wCrgOuAFVXVrkgBvB44BfgAcX1VXtO+sBl7Tqn1dVZ09rpi3xDuAJO3oxtnSeB9w9KSyk4GLq+oQ4OI2D/As4JD2ORF4F9yXZF4LHA48AXhtkr3HGLMkaQZjSxpV9Xlg86TiY4GJlsLZwHNHyt9fgy8BeyXZHzgKuKiqNlfVrcBF/HwikiTNkbm+prFfVd3Ypr8L7NemVwA3jKy3oZVNV/5zkpyYZG2StZs2bZrdqCVJwDxeCK+qAmoW6zujqg6rqsOWL18+W9VKkkbMddK4qXU70f69uZVvBA4cWW9lK5uuXJI0D+Y6aawBVrfp1cAnRsr/MIMnAre3bqwLgCOT7N0ugB/ZyiRJ82Cct9x+GDgC2DfJBoa7oE4Dzk9yAnA98IK2+r8w3G67nuGW2xcDVNXmJH8DXNbWO7WqJl9clyTNkbEljap64TSLnj7FugW8dJp6zgLOmsXQJEnbyCfCJUndTBqSpG4mDUlSN5OGJKmbSUOS1M2kIUnqZtKQJHUzaUiSuo3t4T5pe/jCK2lhsqUhSepm0pAkdTNpSJK6mTQkSd1MGpKkbiYNSVI3k4YkqZtJQ5LUzaQhSepm0pAkdTNpSJK6mTQkSd0csFCLigMZSvPLloYkqZtJQ5LUzaQhSepm0pAkdTNpSJK6mTQkSd1MGpKkbj6noSXN5zqk2WVLQ5LUzaQhSepm95Q0wu4saWa2NCRJ3WxpTGG6vzYlaUdnS0OS1M2WhrSdvA6iHYktDUlSt0WTNJIcneTrSdYnOXm+45GkHdGi6J5Ksgx4B/BMYANwWZI1VXXN/EYmTW/c3VZ2i2k+LIqkATwBWF9V1wIkORc4FjBpaMlYaElmNuMxwS0dqar5jmGLkjwPOLqqXtLm/wA4vKpeNrLOicCJbfaXgK9PqmZf4HtzEO5cc78Wn6W6b+7X4jN53w6qquUzfWGxtDS2qKrOAM6YbnmStVV12ByGNCfcr8Vnqe6b+7X4bMu+LZYL4RuBA0fmV7YySdIcWixJ4zLgkCQHJ9kFOA5YM88xSdIOZ1F0T1XVPUleBlwALAPOqqqrt7KaabuuFjn3a/FZqvvmfi0+W71vi+JCuCRpYVgs3VOSpAXApCFJ6rbkk8ZSHn4kyXVJvprkyiRr5zuebZXkrCQ3J/naSNk+SS5K8o32797zGeO2mGa/TkmysR2zK5McM58xbqskByb5bJJrklyd5KRWvqiP2wz7taiPW5Ldklya5Cttv/66lR+c5JJ2fjyv3Wg0c11L+ZpGG37k/zEy/AjwwqUy/EiS64DDqmpRP3iU5DeAu4D3V9VjW9mbgM1VdVpL9ntX1SvnM86tNc1+nQLcVVVvns/YtleS/YH9q+qKJHsClwPPBY5nER+3GfbrBSzi45YkwB5VdVeS+wFfAE4C/gfwsao6N8m7ga9U1btmqmuptzTuG36kqv4TmBh+RAtIVX0e2Dyp+Fjg7DZ9NsMv7qIyzX4tCVV1Y1Vd0abvBNYBK1jkx22G/VrUanBXm71f+xTwNOAjrbzreC31pLECuGFkfgNL4D/AiAIuTHJ5G0ZlKdmvqm5s098F9pvPYGbZy5Jc1bqvFlX3zVSSrAJ+GbiEJXTcJu0XLPLjlmRZkiuBm4GLgG8Ct1XVPW2VrvPjUk8aS91Tq+pXgGcBL23dIUtODX2oS6Uf9V3Aw4BDgRuBt8xrNNspyQOAjwJ/VlV3jC5bzMdtiv1a9Metqu6tqkMZRtR4AvDIbalnqSeNJT38SFVtbP/eDHyc4T/CUnFT61+e6Ge+eZ7jmRVVdVP75f0J8B4W8TFrfeMfBT5YVR9rxYv+uE21X0vpuFXVbcBngScBeyWZeMi76/y41JPGkh1+JMke7UIdSfYAjgS+NvO3FpU1wOo2vRr4xDzGMmsmTqjNf2WRHrN2YfVMYF1VvXVk0aI+btPt12I/bkmWJ9mrTe/OcHPQOobk8by2WtfxWtJ3TwG0W+Pexk+HH3n9/EY0O5I8lKF1AcNwMB9arPuW5MPAEQzDNN8EvBb4J+B84CHA9cALqmpRXVSeZr+OYOjiKOA64I9HrgEsGkmeCvwf4KvAT1rxqxn6/xftcZthv17IIj5uSR7HcKF7GUNj4fyqOrWdR84F9gG+DPx+Vd09Y11LPWlIkmbPUu+ekiTNIpOGJKmbSUOS1M2kIUnqZtKQJHUzaUjbIMldW15rq+s8dHT01Day6stnezvS9jBpSAvHocCiGnJbOx6ThrSdkvxFksvaYHYT7ylYlWRdkve09xdc2J7EJcmvtXWvTPJ3Sb7WRiw4Ffi9Vv57rfpHJ/lckmuT/Pd52kXpPiYNaTskORI4hGEsokOBXx0ZOPIQ4B1V9RjgNuB3W/l7GZ4oPhS4F6AN3f9XwHlVdWhVndfWfSRwVKv/tW1cJGnemDSk7XNk+3wZuILhJH9IW/atqrqyTV8OrGrj/+xZVf/Ryj+0hfo/VVV3txdt3cwiHmpcS8POW15F0gwCvKGq/uFnCod3MYyO4XMvsPs21D+5Dn9nNa9saUjb5wLgj9r7F0iyIskvTLdyG5b6ziSHt6LjRhbfCew5rkCl2WDSkLZDVV3I0MX0H0m+yvDqzC2d+E8A3tPeorYHcHsr/yzDhe/RC+HSguIot9IcS/KAifc1JzkZ2L+qTprnsKQu9o9Kc+/ZSV7F8Pt3PXD8/IYj9bOlIUnq5jUNSVI3k4YkqZtJQ5LUzaQhSepm0pAkdfv/RdGXpxrCvOcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최대 길이: 29\n",
      "최소 길이: 1\n",
      "평균 길이: 5.651188361667935\n",
      "표준 편차: 2.5598725969048175\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "combined = questions + answers\n",
    "# 텍스트를 토크나이즈하여 토큰 수 계산\n",
    "sentence_lengths = [len(tokenizer.encode(sentence)) for sentence in combined]\n",
    "\n",
    "# 최대, 최소, 평균, 표준편차 계산\n",
    "max_length = np.max(sentence_lengths)\n",
    "min_length = np.min(sentence_lengths)\n",
    "average_length = np.mean(sentence_lengths)\n",
    "std_length = np.std(sentence_lengths)\n",
    "\n",
    "# 히스토그램 그리기\n",
    "plt.hist(sentence_lengths, bins=50)\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Sentence length distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"최대 길이:\", max_length)\n",
    "print(\"최소 길이:\", min_length)\n",
    "print(\"평균 길이:\", average_length)\n",
    "print(\"표준 편차:\", std_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c28746",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = max_length\n",
    "\n",
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 40으로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eb30f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8160\n",
      "필터링 후의 질문 샘플 개수: 11821\n",
      "필터링 후의 답변 샘플 개수: 11821\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d05d07",
   "metadata": {},
   "source": [
    "- val dataset 구성\n",
    "### 현재 사용 안함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52c36868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11300\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "train_size = 11300\n",
    "print(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c36aa817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_not_use():\n",
    "    # 데이터를 질문과 답변을 함께 섞음\n",
    "    random.seed(42)  # 재현 가능한 랜덤 결과를 위해 시드 설정\n",
    "    combined_data = list(zip(questions, answers))\n",
    "    random.shuffle(combined_data)\n",
    "    Q, A = zip(*combined_data)\n",
    "\n",
    "    train_questions = Q[:train_size]\n",
    "    train_answers = A[:train_size]\n",
    "\n",
    "    val_questions = Q[train_size:]\n",
    "    val_answers = A[train_size:]\n",
    "\n",
    "    train_questions = list(train_questions)\n",
    "    train_answers = list(train_answers)\n",
    "\n",
    "    val_questions = list(val_questions)\n",
    "    val_answers = list(val_answers)\n",
    "    print('훈련 질문 샘플 수:', len(train_questions))\n",
    "    print('훈련 답변 샘플 수:', len(train_answers))\n",
    "    print('검증 질문 샘플 수:', len(val_questions))\n",
    "    print('검증 답변 샘플 수:', len(val_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e53c941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용합니다.\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거하겠습니다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3caeb2",
   "metadata": {},
   "source": [
    "#### Step 4. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2717a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4cd8e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64245ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a7ffc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    # 각도 배열 생성\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) \n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "310a79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ce8b1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5f05d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5bd3fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a44e6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)  # Q에 Dense를 적용하여 query를 계산합니다\n",
    "    key = self.key_dense(key)  # K에 Dense를 적용하여 key를 계산합니다\n",
    "    value = self.value_dense(value)  # V에 Dense를 적용하여 value를 계산합니다\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)  # query를 머리 수(num_heads)로 분할합니다\n",
    "    key = self.split_heads(key, batch_size)  # key를 머리 수(num_heads)로 분할합니다\n",
    "    value = self.split_heads(value, batch_size)  # value를 머리 수(num_heads)로 분할합니다\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd9afeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39f33b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "# NUM_LAYERS = 4 # 인코더와 디코더의 층의 개수\n",
    "# D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "# NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "# UNITS = 1024 # 피드 포워드 신경망의 은닉층의 크기\n",
    "# DROPOUT = 0.01 # 드롭아웃의 비율\n",
    "\n",
    "\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 256 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.1 # 드롭아웃의 비율\n",
    "EPOCHS = 20 # 반복횟수\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08d88e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fc9e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.2)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02c2f3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3694.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample_learning_rate = CustomSchedule(d_model=D_MODEL)\n",
    "sample_learning_rate = CustomSchedule(d_model=D_MODEL)\n",
    "total_step = EPOCHS * len(questions)/BATCH_SIZE\n",
    "print(total_step)\n",
    "plt.plot(sample_learning_rate(tf.range(total_step, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4d8dad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f37a6359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "185/185 [==============================] - 15s 47ms/step - loss: 1.6726 - accuracy: 0.0568\n",
      "Epoch 2/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.2780 - accuracy: 0.0752\n",
      "Epoch 3/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 1.1229 - accuracy: 0.0833\n",
      "Epoch 4/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.9858 - accuracy: 0.0918\n",
      "Epoch 5/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.8732 - accuracy: 0.1012\n",
      "Epoch 6/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.7645 - accuracy: 0.1109\n",
      "Epoch 7/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.6667 - accuracy: 0.1220\n",
      "Epoch 8/20\n",
      "185/185 [==============================] - 9s 46ms/step - loss: 0.5919 - accuracy: 0.1319\n",
      "Epoch 9/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.5357 - accuracy: 0.1405\n",
      "Epoch 10/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.4876 - accuracy: 0.1483\n",
      "Epoch 11/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.4476 - accuracy: 0.1563\n",
      "Epoch 12/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.4228 - accuracy: 0.1609\n",
      "Epoch 13/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.4001 - accuracy: 0.1653\n",
      "Epoch 14/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.3816 - accuracy: 0.1697\n",
      "Epoch 15/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.3620 - accuracy: 0.1737\n",
      "Epoch 16/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.3505 - accuracy: 0.1762\n",
      "Epoch 17/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.3445 - accuracy: 0.1780\n",
      "Epoch 18/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.3427 - accuracy: 0.1777\n",
      "Epoch 19/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.3401 - accuracy: 0.1789\n",
      "Epoch 20/20\n",
      "185/185 [==============================] - 9s 47ms/step - loss: 0.3331 - accuracy: 0.1805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d5fe8a2b0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eae4c9",
   "metadata": {},
   "source": [
    "#### Step 5. 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3d3b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)\n",
    "\n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba253479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  prediction = preprocess_sentence(sentence) \n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(prediction)\n",
    "  \n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7824c907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너 바보야?\n",
      "출력 : 잘 될 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 될 거예요 .'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너 바보야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a34fb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 나 너무 피곤한데 어떻게해?\n",
      "출력 : 잘 될 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 될 거예요 .'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"나 너무 피곤한데 어떻게해?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31f47b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너무 단순한 것만 하는거 아니니.\n",
      "출력 : 잘 될 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 될 거예요 .'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너무 단순한 것만 하는거 아니니.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c566706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너무 더워\n",
      "출력 : 잘 될 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 될 거예요 .'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너무 더워\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc4483f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 엄준식은 사람 이름이야 ?\n",
      "출력 : 잘 될 거예요 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'잘 될 거예요 .'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('엄준식은 사람 이름이야 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622152d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
